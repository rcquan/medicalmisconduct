risk_model_2 = x$r_2)
K = 4
risk_quantile_boxplots(list_of_risk_models, K)
risk_quantile_boxplots(list_of_risk_models, K, risk_max = 0.6)
#installs rmap package
install.packages("/Users/Quan/Dropbox/R/rmap_0.01-05.tgz", repos = NULL)
#reading in data set
x = read.csv(
file = "/Users/Quan/Dropbox/R/data_set_score_statistics.csv",
stringsAsFactors = FALSE)
e = x$e
t = x$t
risk_model_1 = list(
r = x$r_1,
Lambda_outcome = x$Lambda_outcome_1,
Lambda_mortality = x$Lambda_mortality_1,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
risk_model_2 = list(
r = x$r_2,
Lambda_outcome = x$Lambda_outcome_2,
Lambda_mortality = x$Lambda_mortality_2,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
ss = score_statistics(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
ss
sr = standardized_residuals(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
plot(sr, grouping_name = "risk")
list_of_risk_models = list(
risk_model_1 = x$r_1,
risk_model_2 = x$r_2)
K = 4
risk_quantile_boxplots(list_of_risk_models, K)
risk_quantile_boxplots(list_of_risk_models, K, risk_max = 0.6)
plot(sr, grouping_name = "risk")
y = read.csv(
file = "/Users/Quan/Dropbox/R/datarandomsample.csv",
stringsAsFactors = FALSE)
y = read.csv(
file = "/Users/Quan/Dropbox/R/datafrandomsample.csv",
stringsAsFactors = FALSE)
y
y = read.csv(
file = "/Users/Quan/Dropbox/R/datafrandomsample.csv",
stringsAsFactors = FALSE)
my_e = x$e
my_t = x$t
my_r = x$r
my_design = "randomSample"
my_riskGroup = list(k = x$k)
my_rSummary = "mean"
my_bootstrap = 30
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
options(width = 120)
options(digits = 3)
rv
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
y = read.csv(
file = "/Users/Quan/Dropbox/R/datafrandomsample.csv",
stringsAsFactors = FALSE)
my_e = y$e
my_t = y$t
my_r = y$r
my_design = "randomSample"
my_riskGroup = list(k = y$k)
my_rSummary = "mean"
my_bootstrap = 30
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
options(width = 120)
options(digits = 3)
rv
#installs rmap package
install.packages("/Users/Quan/Dropbox/R/rmap_0.01-05.tgz", repos = NULL)
#reading in data set
x = read.csv(
file = "/Users/Quan/Dropbox/R/data_set_score_statistics.csv",
stringsAsFactors = FALSE)
#defining e, t as vector
e = x$e
t = x$t
#defining risk models 1 & 2. risk_model requires 4 parameters:
# r = vector, individual risk
#Lambda_outcome = vector, cumulative hazard for outcome
#Lambda_mortality = vector, cumulative hazard for mortality
#groupings = list, any way you want to group (e.g. risk quantiles)
risk_model_1 = list(
r = x$r_1,
Lambda_outcome = x$Lambda_outcome_1,
Lambda_mortality = x$Lambda_mortality_1,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
risk_model_2 = list(
r = x$r_2,
Lambda_outcome = x$Lambda_outcome_2,
Lambda_mortality = x$Lambda_mortality_2,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
#score_statistics, 4 arguments
#(e, t,....) where ... is any number of risk models
#null hypothesis is that the risk model is CORRECT
ss = score_statistics(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
ss
# overall_hosmer_lemeshow    0.5716113 9.119859e-05
# overall_combined           0.5210166 4.811702e-05
# overall_outcome            0.6978251 5.566296e-09
# overall_mortality          0.5927446 5.927446e-01
# weighted_combined          0.4736822 4.771623e-05
# weighted_outcome           0.5864610 5.755802e-09
# weighted_mortality         0.6404587 6.065338e-01
# risk_hosmer_lemeshow       0.3712945 1.627359e+01
# risk_combined              0.8432257 5.270618e-04
# risk_outcome               0.9918845 2.414705e-07
# risk_mortality             0.8393132 9.370315e-01
# missing_hosmer_lemeshow    2.2054854 2.573482e+01
# missing_combined           0.5773268 3.003389e-06
# missing_outcome            0.7254074 2.025474e-16
# missing_mortality          0.7473299 7.473299e-01
#standardized_residuals.
sr = standardized_residuals(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
#plot. This plot is a tool for investigating
#the reasons for poor fit when the null hypothesis is rejected
#The first row contains an attribute diagram for each risk model.
#The second through fourth rows show standardized residual plots for
#combined, outcome, and mortality events respectively.
plot(sr, grouping_name = "risk")
list_of_risk_models = list(
risk_model_1 = x$r_1,
risk_model_2 = x$r_2)
K = 4
#The function risk_model_boxplots creates boxplots of risk quantiles.
#Such boxplots can be useful for judging information loss from grouping the data into quantiles.
risk_quantile_boxplots(list_of_risk_models, K)
risk_quantile_boxplots(list_of_risk_models, K, risk_max = 0.6)
###################################
y = read.csv(
file = "/Users/Quan/Dropbox/R/datafrandomsample.csv",
stringsAsFactors = FALSE)
my_e = y$e
my_t = y$t
my_r = y$r
my_design = "randomSample"
my_riskGroup = list(k = y$k)
my_rSummary = "mean"
my_bootstrap = 30
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
options(width = 120)
options(digits = 3)
rv
#installs rmap package
install.packages("/Users/Quan/Dropbox/R/rmap_0.01-05.tgz", repos = NULL)
#reading in data set
x = read.csv(
file = "/Users/Quan/Dropbox/R/data_set_score_statistics.csv",
stringsAsFactors = FALSE)
#defining e, t as vector
e = x$e
t = x$t
#defining risk models 1 & 2. risk_model requires 4 parameters:
# r = vector, individual risk
#Lambda_outcome = vector, cumulative hazard for outcome
#Lambda_mortality = vector, cumulative hazard for mortality
#groupings = list, any way you want to group (e.g. risk quantiles)
risk_model_1 = list(
r = x$r_1,
Lambda_outcome = x$Lambda_outcome_1,
Lambda_mortality = x$Lambda_mortality_1,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
risk_model_2 = list(
r = x$r_2,
Lambda_outcome = x$Lambda_outcome_2,
Lambda_mortality = x$Lambda_mortality_2,
groupings = list(
risk = list(K = 4),
missing = list(K = 4, variable = x$w)))
#score_statistics, 4 arguments
#(e, t,....) where ... is any number of risk models
#null hypothesis is that the risk model is CORRECT
ss = score_statistics(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
ss
# overall_hosmer_lemeshow    0.5716113 9.119859e-05
# overall_combined           0.5210166 4.811702e-05
# overall_outcome            0.6978251 5.566296e-09
# overall_mortality          0.5927446 5.927446e-01
# weighted_combined          0.4736822 4.771623e-05
# weighted_outcome           0.5864610 5.755802e-09
# weighted_mortality         0.6404587 6.065338e-01
# risk_hosmer_lemeshow       0.3712945 1.627359e+01
# risk_combined              0.8432257 5.270618e-04
# risk_outcome               0.9918845 2.414705e-07
# risk_mortality             0.8393132 9.370315e-01
# missing_hosmer_lemeshow    2.2054854 2.573482e+01
# missing_combined           0.5773268 3.003389e-06
# missing_outcome            0.7254074 2.025474e-16
# missing_mortality          0.7473299 7.473299e-01
#standardized_residuals.
sr = standardized_residuals(e, t,
risk_model_1 = risk_model_1,
risk_model_2 = risk_model_2)
#plot. This plot is a tool for investigating
#the reasons for poor fit when the null hypothesis is rejected
#The first row contains an attribute diagram for each risk model.
#The second through fourth rows show standardized residual plots for
#combined, outcome, and mortality events respectively.
plot(sr, grouping_name = "risk")
list_of_risk_models = list(
risk_model_1 = x$r_1,
risk_model_2 = x$r_2)
K = 4
#The function risk_model_boxplots creates boxplots of risk quantiles.
#Such boxplots can be useful for judging information loss from grouping the data into quantiles.
risk_quantile_boxplots(list_of_risk_models, K)
risk_quantile_boxplots(list_of_risk_models, K, risk_max = 0.6)
###################################
y = read.csv(
file = "/Users/Quan/Dropbox/R/datafrandomsample.csv",
stringsAsFactors = FALSE)
my_e = y$e
my_t = y$t
my_r = y$r
my_design = "randomSample"
my_riskGroup = list(k = y$k)
my_rSummary = "mean"
my_bootstrap = 30
rv = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = my_riskGroup, rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = rvparFn())
options(width = 120)
options(digits = 3)
rv
library(rmap)
set.seed(1)
sampleData = df_randomSample_r1_r2(NTotal = 500)
epsilon = nrow(sampleData)^(-1/3)
tStar = 10
rvu = riskValidateUngrouped(
e = sampleData$e, t = sampleData$t, r = sampleData$r1,
design = "randomSample",
riskGroup = list(
ungrouped = list(epsilon = epsilon, tStar = tStar)),
bootstrap = 20, rvpar = rvparFn(),
multicore = FALSE, verbose = FALSE)
riskGroup = my_riskGroup, rSummary = my_rSummary,
rvu = riskValidateUngrouped(
e = sampleData$e, t = sampleData$t, r = sampleData$r1,
design = "randomSample",
riskGroup = list(
ungrouped = list(epsilon = epsilon, tStar = tStar)),
bootstrap = 20, rvpar = rvparFn(),
multicore = FALSE, verbose = FALSE)
rvu
rv1 = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = list(K = 5), rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = FALSE)
rv2 = riskValidate
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = list(K = 3), rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = FALSE)
attributeDiagram(
rvs = list(rv1, rv2),
rvpar = rvparFn(col = c("blue", "red"),
comment = "rv1 and rv2"))
rv1 = riskValidate(
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = list(K = 5), rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = FALSE)
rv2 = riskValidate
e = my_e, t = my_t, r = my_r, design = my_design,
riskGroup = list(K = 3), rSummary = my_rSummary,
bootstrap = my_bootstrap, rvpar = FALSE)
attributeDiagram(
rvs = list(rv1, rv2),
rvpar = rvparFn(col = c("blue", "red"),
comment = "rv1 and rv2"))
library(rmap)
set.seed(1)
sampleData = df_randomSample_r1_r2(NTotal = 500)
riskGroup = list(
ungrouped = list(epsilon = 0.15, tStar = 10))
rvu1b = riskValidateUngrouped(
e = sampleData$e, t = sampleData$t, r = sampleData$r1,
design = "randomSample", riskGroup = riskGroup, bootstrap = 20,
rvpar = FALSE, multicore = FALSE, verbose = TRUE)
rvu2b = riskValidateUngrouped(
e = sampleData$e, t = sampleData$t, r = sampleData$r2,
design = "randomSample", riskGroup = riskGroup, bootstrap = 20,
rvpar = FALSE, multicore = FALSE, verbose = TRUE)
library(rmap)
set.seed(1)
sampleData = df_randomSample_r1_r2()
riskDensity(
sampleData$e, sampleData$t, sampleData$r1,
tStar = 10, adjust = 1)
install.package("KernSmooth")
install.packages("KernSmooth")
library("KernSmooth", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
detach("package:KernSmooth", unload=TRUE)
read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
read.table("http://http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
read.table("http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
+            sep=",",head=T,row.names=1)
read.table("http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
x<-read.table("http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
+            sep=",",head=T,row.names=1)
x<- read.table("http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",sep=",",head=T,row.names=1)
x
View(x)
summary(x)
freq(x)
?frequency
hist(x)
histogram(x)
bar(x)
boxplot(x)
count(x$chd)
summary(x$chd)
?summary
table(x$chd)
browseVignettes("Iranges")
library("BiocInstaller", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(IRanges)
browseVignettes("Iranges")
ir <- IRanges(5,10)
ir
start(ir)
end(ir)
width(ir)
?IRanges
ir <- IRanges(start=c(3,5,17), end=c(10,8,20))
ir
ir <- IRanges(5,10)
shift(ir, -2)
ir
shift(ir,-2)
narrow(ir, start=2)
narrow(ir, end=5)
flank(ir, width=3, start=TRUE, both=FALSE)
flank(ir, width=3, start=FALSE, both=FALSE)
flank(ir, width=3, start=TRUE, both=TRUE)
plotir <- function(ir,i) { arrows(start(ir)-.5,i,end(ir)+.5,i,code=3,angle=90,lwd=3) }
plotir <- function(ir,i) { arrows(start(ir)-.5,i,end(ir)+.5,i,code=3,angle=90,lwd=3) }
plot(0,0,xlim=c(0,15),ylim=c(0,8),type="n",xlab="",ylab="",xaxt="n")
axis(1,0:15)
abline(v=0:30 + .5,col=rgb(0,0,0,.5))
# plot the original IRange
plotir(ir,1)
polygon(c(start(ir)-.5,start(ir)-.5,end(ir)+.5,end(ir)+.5),c(-1,9,9,-1),col=rgb(1,0,0,.2),border=NA)
plotir(shift(ir,-2), 2)
plotir(narrow(ir, start=2), 3)
plotir(narrow(ir, end=5), 4)
plotir(flank(ir, width=3, start=TRUE, both=FALSE), 5)
plotir(flank(ir, width=3, start=FALSE, both=FALSE), 6)
plotir(flank(ir, width=3, start=TRUE, both=TRUE), 7)
ir <- IRanges(start=c(3,5,17), end=c(10,8,20))
range(ir)
reduce(ir)
gaps(ir)
disjoin(ir)
library(GenomicRanges)
gr <- GRanges("chrZ", IRanges(start=c(5,10),end=c(35,45)),
strand="+", seqlengths=c(chrZ=100L))
gr
library(GenomicRanges)
install.packages("GenomicRanges")
library(Genomicranges)
install.packages("Bioconductor")
library(GenomicRanges)
gr <- GRanges("chrZ", IRanges(start=c(5,10),end=c(35,45)),
strand="+", seqlengths=c(chrZ=100L))
install.packages("GenomicRanges")
install.packages("Bioconductor")
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite()
source("http://bioconductor.org/biocLite.R")
install.packages("BiocInstaller",
repos="http://www.bioconductor.org/packages/2.14/bioc")
install.packages("BiocInstaller", repos="http://bioconductor.org/packages/2.13/bioc")
source("http://bioconductor.org/biocLite.R")
biocLite("BiocInstaller")
install.packages("knitr")
library(knitr)
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
source("http://bioconductor.org/biocLite.R")
biocLite("BiocInstaller")
source("bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R"); biocLite()
ource("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite()
source("http://bioconductor.org/biocLite.R")
biocLite()
"use 'install.packages("BiocInstaller", repos="http://www.bioconductor.org/packages/2.12/bioc")"
install.packages("BiocInstaller", repos="http://www.bioconductor.org/packages/2.12/bioc")
install.packages("BiocInstaller", repos="http://www.bioconductor.org/packages/2.14/bioc")
install.packages("BiocInstaller", repos="http://www.bioconductor.org/packages/2.13/bioc")
source("http://bioconductor.org/biocLite.R")
biocLite()
medmis <- read.csv("20140504_Medical Misconduct_CompleteCase.csv")
AED <- medmis$Age.at.Effective.Date
mean(AED, na.rm = TRUE)
hist(AED)
bar(med)
date <- as.character(medmis$Effective.Date)
date <- as.Date(date,"%m/%d/%y")
medMis <- read.csv(fileName)
# Exploratory Data Analysis
str(medMis)
table(medMis$Year.of.Birth, useNA = "ifany") # 192315, NA = 1610
# Creates data frame of multiple offenders
y <- as.data.frame(table(medMis$Name))
setwd("~/GitHub/medicalmisconduct")
medMis <- read.csv(fileName)
# Exploratory Data Analysis
str(medMis)
table(medMis$Year.of.Birth, useNA = "ifany") # 192315, NA = 1610
# Creates data frame of multiple offenders
y <- as.data.frame(table(medMis$Name))
fileName = "medMis.csv"
if (!file.exists(fileName)){
url <- "https://health.data.ny.gov/api/views/ebmi-8ctw/rows.csv?accessType=DOWNLOAD"
fileName <- "medMis.csv"
download.file(url, fileName, method = "curl")
}
medMis <- read.csv(fileName)
# Exploratory Data Analysis
str(medMis)
table(medMis$Year.of.Birth, useNA = "ifany") # 192315, NA = 1610
# Creates data frame of multiple offenders
y <- as.data.frame(table(medMis$Name))
View(y)
View(medMis)
medMis <- merge(medMis, y, by.x = "Name", by.y = "Var1"
)
View(medMis)
colnames(multi) <- c("Name", "Name.Freq")
multi <- as.data.frame(table(medMis$Name))
colnames(multi) <- c("Name", "Name.Freq")
medMis <- merge(medMis, multi)
medMis <- read.csv(fileName)
# Exploratory Data Analysis
str(medMis)
table(medMis$Year.of.Birth, useNA = "ifany") # 192315, NA = 1610
# Creates data frame of multiple offenders
multi <- as.data.frame(table(medMis$Name))
colnames(multi) <- c("Name", "Name.Freq")
medMis <- merge(medMis, multi)
with(medMis, table(medMis$Name)[table(medMis$Name) > 1) # Give the TRUE indices
with(medMis, table(medMis$Name)[table(medMis$Name) > 1] # Give the TRUE indices
with(medMis, table(medMis$Name)[table(medMis$Name) > 1]) # Give the TRUE indices
require(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
class(medMis$Effective.Date)
medMis$Effective.Date <- as.character(medMis$Effective.Date)
medMis$Effective.Date <- as.POSIXct(medMis$Effective.Date, format = "%m/%d/%Y")
class(medMis$Effective.Date)
medMis_xts <- as.xts(medMis, order.by = "Effective.Date")
medMis_xts <- as.xts(medMis, order.by = medMis$Effective.Date)
View(medMis_xts)
medMis_xts['2012']
head(medMis_xts)
head(medMis_xts, n = 1)
View(medMis_xts)
View(medMis_xts)
plot.xts(medMis_xts)
data(sample_matrix)
View(sample_matrix)
plot(medMis_xts$Name.Freq)
plot(medMis_xts)
plot(medMis_xts['2012'])
